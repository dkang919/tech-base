{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Sea of Iteration: Where Data Meets Improvement"},{"location":"index-reserve/","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"index-reserve/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"index-reserve/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre> <p>Set-ExecutionPolicy RemoteSigned -Scope Process</p> <p>.\\venv\\Scripts\\activate</p> <p>mkdocs serve</p> <p>python -m mkdocs serve</p>"},{"location":"aar/2026-01-21%20copy/","title":"\ud83d\udcc4 AAR: 2026 Toastmasters International Speech Contest","text":"<p>Tags: #AAR #Fail_Log #Toastmasters #Retest_Required Date: 2026-01-21 Status: \ud83d\udfe0 Open Loop (Waiting for Validation)</p>"},{"location":"aar/2026-01-21%20copy/#1-intention","title":"1. \ucd08\uae30 \uc758\ub3c4 (Intention)","text":"<p>What was supposed to happen?</p> <ul> <li>Win a club level international speech contest at my Toastmaster club.</li> </ul>"},{"location":"aar/2026-01-21%20copy/#2-result","title":"2. \uc2e4\uc81c \uacb0\uacfc (Result)","text":"<p>What actually happened?</p> <ul> <li>Did not prepare the script despite having 2 months (since Dec).</li> <li>Withdrew from the contest as I was not prepared.</li> </ul>"},{"location":"aar/2026-01-21%20copy/#3-gap-analysis","title":"3. \ucc28\uc774\uc758 \uc6d0\uc778 (Gap Analysis)","text":"<p>Why was there a difference? [Root Cause]</p> <ul> <li>Preparation Failure: Failed to specify enough time to finalize the script. Did not prepare the script in advance.</li> <li>Overconfidence: Thought I had most things covered in my head, leading to procrastination.</li> <li>Fragmented Focus: Had too many plans for various parties (friends, dates, community, work, side-projects, workout).</li> <li>Root Cause: Built too many goals simultaneously. This led to a fragmented time budget and partitioned focus, pushing the timeline for tasks I underestimated.</li> </ul>"},{"location":"aar/2026-01-21%20copy/#4-action-plan","title":"4. \ud5a5\ud6c4 \uacc4\ud68d (Action Plan)","text":"<p>What will we do differently? [System Update]</p>"},{"location":"aar/2026-01-21%20copy/#start","title":"\ud83d\udfe2 Start (\uc0c8\ub85c \uc2dc\uc791\ud560 \uac83)","text":"<ul> <li>Target 'Done' over 'Perfect': Lower the goal to get back to the habit of completion. Draft first, polish later.</li> <li>The 'Half-way' Rule: \uc2a4\ud53c\uce58 \uc608\uc57d \uc2dc\uc810\ubd80\ud130 \ubc1c\ud45c\uc77c\uae4c\uc9c0 \ub531 \uc911\uac04 \uc9c0\uc810\uc5d0 \ucd08\uc548(Draft)\uc774 \uc5c6\uc73c\uba74, \ud004\ub9ac\ud2f0 \ubd88\ubb38\ud558\uace0 \ubb34\uc870\uac74 \ud29c\ud130/\uba58\ud1a0\uc5d0\uac8c \ubcf4\uc5ec\uc8fc\uace0 \ud53c\ub4dc\ubc31\uc744 \uac15\uc81c\ub85c \ubc1b\ub294\ub2e4.</li> <li>Time Budgeting: Buy enough time budget and plan exactly what I want to finish on a scheduled date.</li> </ul>"},{"location":"aar/2026-01-21%20copy/#stop","title":"\ud83d\udd34 Stop (\uadf8\ub9cc\ub458 \uac83)","text":"<ul> <li>Limit Active Projects to 3: Don't plan too much. \ub3d9\uc2dc\uc5d0 \uc9c4\ud589\ud558\ub294 \uc911\uc694 \ud504\ub85c\uc81d\ud2b8/\uc57d\uc18d\uc744 3\uac1c \uc774\ud558\ub85c \uc81c\ud55c\ud55c\ub2e4. \ud558\ub098\uac00 \ub05d\ub098\uae30 \uc804\uc5d4 \uc0c8 \uc57d\uc18d\uc744 \uc7a1\uc9c0 \uc54a\ub294\ub2e4.</li> </ul>"},{"location":"aar/2026-01-21%20copy/#continue","title":"\ud83d\udd35 Continue (\uc720\uc9c0\ud560 \uac83)","text":"<ul> <li>Plan ahead of the time.</li> </ul>"},{"location":"aar/2026-01-21%20copy/#rules-kill-criteria","title":"\u26a0\ufe0f Rules (Kill Criteria)","text":"<ul> <li>The \"D-7 Kill Switch\": Get a drawback plan in advance. \ud589\uc0ac 7\uc77c \uc804\uae4c\uc9c0 \ub9ac\ud5c8\uc124 \uac00\ub2a5\ud55c \uc0c1\ud0dc\uac00 \uc544\ub2c8\uba74, \uadf8 \uc989\uc2dc \ud3ec\uae30 \uc120\uc5b8\uc744 \ud55c\ub2e4. (\ud589\uc0ac \uc9c1\uc804 \ud3ec\uae30 \ubc29\uc9c0)</li> </ul>"},{"location":"aar/2026-01-21%20copy/#5-validation","title":"5. \u2705 \uc131\uacf5 \uac80\uc99d (Validation)","text":"<p>[Open Loop]</p> <ul> <li>(This section is intentionally left blank.)</li> <li>(To be filled when the Action Plan is successfully applied in a similar future event.)</li> </ul>"},{"location":"aar/2026-01-21/","title":"\ud83d\udcc4 AAR: 2026 Toastmasters International Speech Contest","text":"<p>Tags: #AAR #Fail_Log #Toastmasters #Retest_Required Date: 2026-01-21 Status: \ud83d\udfe0 Open Loop (Waiting for Validation)</p>"},{"location":"aar/2026-01-21/#1-intention","title":"1. Intention","text":"<p>What was supposed to happen?</p> <ul> <li>Win a club level international speech contest at my Toastmaster club.</li> </ul>"},{"location":"aar/2026-01-21/#2-result","title":"2. Result","text":"<p>What actually happened?</p> <ul> <li>Did not prepare the script despite having 2 months (since Dec).</li> <li>Withdrew from the contest as I was not prepared.</li> </ul>"},{"location":"aar/2026-01-21/#3-gap-analysis","title":"3. Gap Analysis","text":"<p>Why was there a difference? [Root Cause]</p> <ul> <li>Preparation Failure: Failed to specify enough time to finalize the script. Did not prepare the script in advance.</li> <li>Overconfidence: Thought I had most things covered in my head, leading to procrastination.</li> <li>Fragmented Focus: Had too many plans for various parties (friends, dates, community, work, side-projects, workout).</li> <li>Root Cause: Built too many goals simultaneously. This led to a fragmented time budget and partitioned focus, pushing the timeline for tasks I underestimated.</li> </ul>"},{"location":"aar/2026-01-21/#4-action-plan","title":"4. Action Plan","text":"<p>What will we do differently? [System Update]</p>"},{"location":"aar/2026-01-21/#start","title":"\ud83d\udfe2 Start","text":"<ul> <li>Target 'Done' over 'Perfect': Lower the goal to get back to the habit of completion. Draft first, polish later.</li> <li>The 'Half-way' Rule: \uc2a4\ud53c\uce58 \uc608\uc57d \uc2dc\uc810\ubd80\ud130 \ubc1c\ud45c\uc77c\uae4c\uc9c0 \ub531 \uc911\uac04 \uc9c0\uc810\uc5d0 \ucd08\uc548(Draft)\uc774 \uc5c6\uc73c\uba74, \ud004\ub9ac\ud2f0 \ubd88\ubb38\ud558\uace0 \ubb34\uc870\uac74 \ud29c\ud130/\uba58\ud1a0\uc5d0\uac8c \ubcf4\uc5ec\uc8fc\uace0 \ud53c\ub4dc\ubc31\uc744 \uac15\uc81c\ub85c \ubc1b\ub294\ub2e4.</li> <li>Time Budgeting: Buy enough time budget and plan exactly what I want to finish on a scheduled date.</li> </ul>"},{"location":"aar/2026-01-21/#stop","title":"\ud83d\udd34 Stop","text":"<ul> <li>Limit Active Projects to 3: Don't plan too much. \ub3d9\uc2dc\uc5d0 \uc9c4\ud589\ud558\ub294 \uc911\uc694 \ud504\ub85c\uc81d\ud2b8/\uc57d\uc18d\uc744 3\uac1c \uc774\ud558\ub85c \uc81c\ud55c\ud55c\ub2e4. \ud558\ub098\uac00 \ub05d\ub098\uae30 \uc804\uc5d4 \uc0c8 \uc57d\uc18d\uc744 \uc7a1\uc9c0 \uc54a\ub294\ub2e4.</li> </ul>"},{"location":"aar/2026-01-21/#continue","title":"\ud83d\udd35 Continue","text":"<ul> <li>Plan ahead of the time.</li> </ul>"},{"location":"aar/2026-01-21/#rules-kill-criteria","title":"\u26a0\ufe0f Rules (Kill Criteria)","text":"<ul> <li>The \"D-7 Kill Switch\": Get a drawback plan in advance. \ud589\uc0ac 7\uc77c \uc804\uae4c\uc9c0 \ub9ac\ud5c8\uc124 \uac00\ub2a5\ud55c \uc0c1\ud0dc\uac00 \uc544\ub2c8\uba74, \uadf8 \uc989\uc2dc \ud3ec\uae30 \uc120\uc5b8\uc744 \ud55c\ub2e4. (\ud589\uc0ac \uc9c1\uc804 \ud3ec\uae30 \ubc29\uc9c0)</li> </ul>"},{"location":"aar/2026-01-21/#5-validation","title":"5. \u2705 Validation","text":"<p>[Open Loop]</p> <ul> <li>I have one upcoming speech, once I secure the booking. I will follow the plan</li> <li>(To be filled when the Action Plan is successfully applied in a similar future event.)</li> </ul>"},{"location":"projects/ca-pc-parts-tracker/","title":"\ud83d\udda5\ufe0f Canada PC Parts Price Tracker &amp; Insights","text":"<p>This project collects and analyzes computer part price data from major Canadian retailers.</p>"},{"location":"projects/ca-pc-parts-tracker/#project-goal","title":"\ud83d\udca1 Project Goal","text":"<ul> <li>Why: To identify price fluctuation trends in the Canadian computer parts market.</li> <li>How: By tracking historical data to predict the optimal purchase timing for key components like GPUs.</li> <li>Result: Deriving market insights through data visualization.</li> </ul>"},{"location":"projects/ca-pc-parts-tracker/#planned-tech-stack","title":"\ud83d\udee0 Planned Tech Stack","text":"<ul> <li>Data Collection: Python (BeautifulSoup, Selenium)</li> <li>Storage: PostgreSQL / Google BigQuery</li> <li>Analysis: Pandas, Scikit-learn</li> <li>Visualization: Plotly (Interactive Charts)</li> </ul>"},{"location":"projects/ca-pc-parts-tracker/#ram-price-trend","title":"\ud83d\udcca RAM Price Trend","text":"<p>(Insert your chart image here, e.g., <code>![RAM Trend](../images/ram_price_trend.png)</code>)</p>"},{"location":"projects/iec-monitor/","title":"\ud83c\udde8\ud83c\udde6 Canada IEC Working Holiday Monitor","text":"<p>An automation bot that detects Canada Working Holiday invitation rounds in real-time and sends notifications.</p>"},{"location":"projects/iec-monitor/#project-background","title":"\ud83d\udca1 Project Background","text":"<ul> <li>Why: Canada Working Holiday invitations are sent out unexpectedly. Checking the official website manually is inefficient.</li> <li>How: I built a system that \"sends a notification to my phone as soon as a change is detected.\"</li> </ul>"},{"location":"projects/iec-monitor/#tech-stack","title":"\ud83d\udee0 Tech Stack","text":"<ul> <li>Language: Python</li> <li>Cloud: GCP (Cloud Run, Firestore)</li> <li>DevOps: Docker, GitHub Actions</li> <li>Notification: Telegram API</li> </ul>"},{"location":"projects/iec-monitor/#key-features","title":"\ud83d\ude80 Key Features","text":"<ol> <li>Automated Scraping: Scans the official website status once per day (cycle optimized based on user feedback).</li> <li>Change Detection: Detects changes by comparing the hash values of the previous and current states.</li> <li>Instant Alert: Sends an immediate push notification via Telegram when a change is detected.</li> </ol>"},{"location":"projects/iec-monitor/#impact","title":"\ud83d\udcc8 Impact","text":"<ul> <li>Validation: Shared on social media, achieving 40 Likes on LinkedIn, confirming high interest from actual users.</li> <li>Optimization: Improved efficiency and reduced notification fatigue by adjusting the alert cycle from every 10 minutes to once per day.</li> </ul>"},{"location":"study/ab-testing/","title":"A/B Testing: The Gold Standard of Causality","text":"<p>Top-Line Summary: A/B Testing (or Split Testing) is the application of the scientific method (Randomized Controlled Trials) to product development. In the tech industry, we do not guess; we experiment.</p> <ul> <li>The Goal: Isolate the impact of a specific change (Variable) on a specific metric (Outcome).</li> <li>The Mechanism: Randomly split users into two groups: Control (Group A, sees the old version) and Treatment (Group B, sees the new version).</li> <li>The Key: Since the split is random, the only difference between the groups is your change. Therefore, any difference in metrics is caused by your change.</li> </ul>"},{"location":"study/ab-testing/#1-the-mathematical-intuition-the-professor","title":"1. The Mathematical Intuition (The Professor)","text":""},{"location":"study/ab-testing/#hypothesis-testing","title":"Hypothesis Testing","text":"<p>We start with two hypotheses: * Null Hypothesis (\\(H_0\\)): The change does nothing. The conversion rate of A is equal to B (\\(p_A = p_B\\)). * Alternative Hypothesis (\\(H_1\\)): The change does something. (\\(p_A \\neq p_B\\) or \\(p_B &gt; p_A\\)).</p>"},{"location":"study/ab-testing/#the-four-statistical-pillars","title":"The Four Statistical Pillars","text":"<p>To run a valid test, you must define these before you start:</p> <ol> <li>Significance Level (\\(\\alpha\\)): Usually 0.05 (5%).<ul> <li>The risk of a Type I Error (False Positive).</li> <li>\"We claim the new feature is better, but it's actually not.\"</li> </ul> </li> <li>Statistical Power (\\(1 - \\beta\\)): Usually 0.80 (80%).<ul> <li>The probability of correctly detecting an effect if one exists.</li> <li>\\(\\beta\\) is the risk of a Type II Error (False Negative: missing a good idea).</li> </ul> </li> <li>Minimum Detectable Effect (MDE):<ul> <li>The smallest improvement that matters to the business.</li> <li>Example: \"We only care if conversion improves by at least 1%.\" If it improves by 0.01%, it's not worth the engineering cost.</li> </ul> </li> <li>Sample Size (\\(N\\)):<ul> <li>Calculated using \\(\\alpha\\), Power, and MDE.</li> <li>Rule: Smaller MDE requires larger sample size. Detecting a tiny needle requires a huge haystack.</li> </ul> </li> </ol>"},{"location":"study/ab-testing/#the-test-statistic-z-test","title":"The Test Statistic (Z-Test)","text":"<p>For conversion rates (proportions), we typically use a Two-Proportion Z-Test:</p> \\[Z = \\frac{\\hat{p}_B - \\hat{p}_A}{\\sqrt{ \\hat{p}_{pool}(1 - \\hat{p}_{pool}) (\\frac{1}{n_A} + \\frac{1}{n_B}) }}\\] <p>If the resulting p-value is \\(&lt; \\alpha\\) (0.05), we reject the Null Hypothesis. The result is \"Statistically Significant.\"</p>"},{"location":"study/ab-testing/#2-engineering-production-reality-the-principal-engineer","title":"2. Engineering &amp; Production Reality (The Principal Engineer)","text":""},{"location":"study/ab-testing/#a-randomization-the-hashing-trick","title":"A. Randomization (The Hashing Trick)","text":"<p>How do we randomly assign 100 million users to Group A or B efficiently? We don't store a database row for each user saying \"User1: A\". That's too slow.</p> <p>We use Hashing: 1.  Take <code>User_ID</code> + <code>Experiment_Salt</code> (e.g., \"User123\" + \"CheckoutTest\"). 2.  Compute a hash (MD5 or SHA256). 3.  Convert to an integer and take Modulo 100. 4.  If result &lt; 50: Assign to Control. If &gt;= 50: Assign to Treatment.</p> <p>Benefit: This is deterministic (User123 is always in the same group) and stateless (no database lookup needed).</p>"},{"location":"study/ab-testing/#b-metric-selection-the-hierarchy","title":"B. Metric Selection: The Hierarchy","text":"<p>You need more than just one metric.</p> <ul> <li>North Star (Primary) Metric: The goal (e.g., Conversion Rate, Click-Through Rate).</li> <li>Guardrail Metrics: Things you cannot hurt.<ul> <li>Example: You increase Clicks by 10% (Great!), but Page Load Latency goes up by 200ms (Bad!). You must kill the experiment.</li> <li>Example: You increase Revenue, but Unsubscribe Rate spikes.</li> </ul> </li> </ul>"},{"location":"study/ab-testing/#c-the-peeking-sin","title":"C. The \"Peeking\" Sin","text":"<p>CRITICAL: Do Not Peek</p> <p>The Scenario: You run a test for 2 days. P-value is 0.04. You shout \"Success!\" and stop.</p> <p>The Reality: P-values fluctuate wildly at the start (\"Random Walk\").</p> <p>The Rule: You must decide the sample size/duration beforehand (e.g., 7 days) and not look (or at least not act) until the time is up.</p>"},{"location":"study/ab-testing/#d-novelty-effect-primacy-effect","title":"D. Novelty Effect &amp; Primacy Effect","text":"<ul> <li>Novelty Effect: Users click the new button just because it's new. The lift fades after 1 week.</li> <li>Primacy Effect: Users hate change. Metrics dip initially because they are confused, then recover.</li> </ul> <p>Engineering Fix</p> <p>Run experiments for at least 1-2 full business cycles (e.g., 2 weeks) to let these effects wash out and capture weekly seasonality (e.g., users behave differently on weekends).</p>"},{"location":"study/ab-testing/#e-the-final-reality-check","title":"E. The Final Reality Check","text":"<p>\"Statistical Significance \\(\\neq\\) Practical Significance\"</p> <p>Imagine you test a change on 100 million users (Google scale). * Result: You improved conversion from 2.0% to 2.0001%. * P-value: 0.001 (Highly Significant!).</p> <p>The Business Question</p> <p>Does that 0.0001% increase cover the cost of maintaining this new code?</p> <p>If the answer is No, you should still reject the change, even if the math says it's \"significant.\" Always weigh the lift against the technical debt.</p>"},{"location":"study/decision_tree/","title":"Decision Trees: The Interpretable \"Flowchart\" of Machine Learning","text":"<p>Top-Line Summary: A Decision Tree is a non-parametric algorithm that models decisions as a flowchart-like structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed.</p> <ul> <li>The Superpower: It requires almost no data preparation (no scaling/normalization) and is easily visualized.</li> <li>The Kryptonite: A single tree is extremely prone to overfitting. It will memorize your training data perfectly (high variance) and fail on new data unless you constrain it.</li> </ul>"},{"location":"study/decision_tree/#1-the-intuition-20-questions-the-professor","title":"1. The Intuition: \"20 Questions\" (The Professor)","text":"<p>Imagine I am thinking of a transaction type, and you have to guess if it is Fraud.</p> <ol> <li>You: \"Is the amount &gt; $10,000?\"</li> <li>Me: \"Yes.\"</li> <li>You: \"Did the transaction originate in a different country?\"</li> <li>Me: \"Yes.\"</li> <li>You: \"Fraud!\"</li> </ol> <p>The Decision Tree algorithm figures out which question to ask first to separate the data most effectively.</p>"},{"location":"study/decision_tree/#the-anatomy-of-a-tree","title":"The Anatomy of a Tree","text":"<ul> <li>Root Node: Represents the entire population. The first best question.</li> <li>Decision Node: A sub-node that splits into further sub-nodes.</li> <li>Leaf Node (Terminal Node): A node that does not split. It holds the final prediction (e.g., \"Fraud\").</li> </ul>"},{"location":"study/decision_tree/#2-the-math-how-it-chooses-the-split","title":"2. The Math: How It Chooses the Split","text":"<p>The model tries every possible split on every feature and calculates a metric to see which split makes the resulting child nodes the most \"pure.\"</p>"},{"location":"study/decision_tree/#metric-a-gini-impurity-the-industry-standard","title":"Metric A: Gini Impurity (The Industry Standard)","text":"<p>Used by the CART algorithm (Classification and Regression Trees). It measures the likelihood of an incorrect classification of a new instance of a random variable, if that new instance were randomly classified according to the distribution of class labels from the dataset.</p> \\[Gini = 1 - \\sum_{i=1}^{C} (p_i)^2\\] <ul> <li>\\(p_i\\): The probability of an item belonging to class \\(i\\).</li> <li>Gini = 0: Perfect purity (all items in the node are the same class).</li> <li>Gini = 0.5: Maximum impurity (for binary classification, a 50/50 split).</li> </ul> <p>The Goal: We want the split that results in the lowest weighted average Gini Impurity for the child nodes.</p>"},{"location":"study/decision_tree/#metric-b-entropy-information-gain","title":"Metric B: Entropy &amp; Information Gain","text":"<p>Derived from Information Theory. Entropy measures the amount of \"disorder\" or uncertainty.</p> \\[Entropy = - \\sum_{i=1}^{C} p_i \\log_2(p_i)\\] <ul> <li>Entropy = 0: No disorder (Perfect purity).</li> <li>Information Gain: The reduction in entropy after a dataset is split on an attribute. The tree maximizes Information Gain.</li> </ul> <p>Professor's Note</p> <p>In practice, Gini and Entropy produce very similar trees 95% of the time. Gini is slightly faster to compute because it doesn't use logarithms.</p>"},{"location":"study/decision_tree/#3-regression-trees-predicting-numbers","title":"3. Regression Trees (Predicting Numbers)","text":"<p>If you are predicting a continuous value (like House Price) instead of a category:</p> <ul> <li>The metric is not Gini, but MSE (Variance) Reduction.</li> <li>The tree splits to minimize the variance of the values in the child nodes.</li> <li>Prediction: The prediction at the leaf node is the Average (Mean) of all training samples in that leaf.</li> </ul>"},{"location":"study/decision_tree/#4-engineering-production-reality-the-principal-engineer","title":"4. Engineering &amp; Production Reality (The Principal Engineer)","text":""},{"location":"study/decision_tree/#a-the-overfitting-trap","title":"A. The Overfitting Trap","text":"<p>A Decision Tree will keep splitting until every leaf is pure. If you have two identical customers but one churned and one didn't, the tree will find some obscure noise (\"User clicked button at 4:02 PM vs 4:03 PM\") to distinguish them.</p> <ul> <li>Result: 100% Training Accuracy, 60% Test Accuracy.</li> <li>The Fix: Pruning (Constraints).</li> </ul>"},{"location":"study/decision_tree/#b-crucial-hyperparameters-your-knobs-dials","title":"B. Crucial Hyperparameters (Your Knobs &amp; Dials)","text":"<p>When deploying a tree, you must set these:</p> <ul> <li><code>max_depth</code>: The maximum height of the tree. A depth of 3 to 5 is usually interpretable and generalizable. A depth of 50 is pure noise.</li> <li><code>min_samples_split</code>: The minimum number of samples required to split an internal node. If set to 100, a node with 50 samples becomes a leaf (stops growing).</li> <li><code>min_samples_leaf</code>: The minimum samples a leaf node must have. Prevents the tree from creating a leaf for a single outlier.</li> </ul>"},{"location":"study/decision_tree/#c-feature-scaling-is-irrelevant","title":"C. Feature Scaling is Irrelevant","text":"<p>Unlike Logistic Regression or Neural Networks, Decision Trees do not care about the scale of your data.</p> <ul> <li>Feature A: 0.0 to 1.0</li> <li>Feature B: $1,000 to $1,000,000</li> </ul> <p>The tree just asks: \"Is Feature B &gt; $500,000?\" It is strictly orthogonal.</p>"},{"location":"study/evaluation_metrics/","title":"Machine Learning Metrics: Theory vs. Practice","text":""},{"location":"study/evaluation_metrics/#part-1-regression-metrics-predicting-continuous-values","title":"Part 1: Regression Metrics (Predicting Continuous Values)","text":"<p>These metrics are used when you are predicting a number (e.g., House Price, Eta for a taxi, Server Latency).</p>"},{"location":"study/evaluation_metrics/#1-mean-absolute-error-mae","title":"1. Mean Absolute Error (MAE)","text":"<p>The Professor (Theory): The arithmetic average of the absolute differences between predicted and actual values. It treats all errors equally.</p> \\[MAE = \\frac{1}{n}\\sum_{i=1}^{n} |y_i - \\hat{y}_i|\\] <p>The Engineer (Practice): * Why use it? It is robust to outliers. If your dataset has a few \"crazy\" values (e.g., a mansion selling for $100M in a neighborhood of $500k homes), MAE won't skew your entire model to fit that one mansion. * Production Note: It is highly interpretable for stakeholders. You can tell a Product Manager: \"Our model is off by an average of $5.00.\"</p>"},{"location":"study/evaluation_metrics/#2-root-mean-squared-error-rmse","title":"2. Root Mean Squared Error (RMSE)","text":"<p>The Professor (Theory): The square root of the average of squared differences. Because we square the error, larger errors are penalized disproportionately more than small errors.</p> \\[RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\\] <p>The Engineer (Practice): * Why use it? In many systems (like self-driving cars or stock trading), one huge mistake is worse than many small ones. RMSE forces the model to care deeply about preventing those huge misses. * Pitfall: If you have noisy data with many outliers, RMSE might force your model to overfit to that noise.</p>"},{"location":"study/evaluation_metrics/#part-2-classification-metrics-predicting-categories","title":"Part 2: Classification Metrics (Predicting Categories)","text":"<p>These are used when predicting a class (e.g., Spam/Not Spam, Fraud/Not Fraud).</p>"},{"location":"study/evaluation_metrics/#3-accuracy","title":"3. Accuracy","text":"<p>The Professor (Theory): The ratio of correct predictions to total predictions.</p> \\[Accuracy = \\frac{TP + TN}{Total \\ Examples}\\] <p>The Engineer (Practice): * The Trap: Never trust accuracy on imbalanced data. * Scenario: You are building a Fraud Detector. 99.9% of transactions are legit. If you write a code that just says \"Not Fraud\" for everything, your accuracy is 99.9%. But you caught 0 fraud. The model is useless.</p>"},{"location":"study/evaluation_metrics/#4-5-precision-recall-the-trade-off","title":"4 &amp; 5. Precision &amp; Recall (The Trade-off)","text":"<p>The Professor (Theory): * Precision: Of all the instances predicted as positive, how many were actually positive? (Quality).     $\\(Precision = \\frac{TP}{TP + FP}\\)$ * Recall (Sensitivity): Of all the actual positive instances, how many did we correctly predict? (Quantity).     $\\(Recall = \\frac{TP}{TP + FN}\\)$</p> <p>The Engineer (Practice): You cannot maximize both. You must choose based on business cost. * Optimize Precision: If a False Positive is expensive.     * Example: YouTube Kids Content Filter. You'd rather miss a few bad videos (Low Recall) than accidentally ban a legitimate educational creator (High Precision needed). * Optimize Recall: If a False Negative is dangerous.     * Example: Cancer Screening. It is better to flag a healthy person for a re-check (False Positive) than to tell a sick person they are healthy (False Negative).</p>"},{"location":"study/evaluation_metrics/#6-f1-score","title":"6. F1 Score","text":"<p>The Professor (Theory): The Harmonic Mean of Precision and Recall. It penalizes extreme values. If either Precision or Recall is 0, the F1 score is 0.</p> \\[F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\\] <p>The Engineer (Practice): * Why use it? It gives you a single number to compare models when you have uneven class distribution (e.g., 90% class A, 10% class B). It prevents the \"Accuracy Trap.\"</p>"},{"location":"study/evaluation_metrics/#7-roc-auc-area-under-the-receiver-operating-characteristic-curve","title":"7. ROC-AUC (Area Under the Receiver Operating Characteristic Curve)","text":"<p>The Professor (Theory): A plot of True Positive Rate vs. False Positive Rate at all possible classification thresholds. AUC (Area Under Curve) represents the probability that the model ranks a random positive example higher than a random negative example.</p> <p>The Engineer (Practice): * Why use it? It is threshold invariant. It tells you how good the model is generally, before you even decide on a cut-off point (e.g., \"Flag fraud if probability &gt; 0.7\"). * Scale: Standard for comparing models offline before deploying.</p>"},{"location":"study/evaluation_metrics/#8-log-loss-cross-entropy-loss","title":"8. Log Loss (Cross-Entropy Loss)","text":"<p>The Professor (Theory): Measures the performance of a classification model where the prediction input is a probability value between 0 and 1. It heavily penalizes confident wrong predictions.</p> \\[LogLoss = - \\frac{1}{N} \\sum_{i=1}^{N} [y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i)]\\] <p>The Engineer (Practice): * Why use it? Critical for Ad-Tech and Click-Through Rate (CTR) prediction. * The Nuance: Accuracy doesn't care if you predicted 0.51 (barely yes) or 0.99 (definitely yes). Log Loss does. If your model says \"99% chance this is a cat\" and it's a dog, Log Loss explodes. It forces the model to be calibrated (honest about its uncertainty).</p>"},{"location":"study/logistic_regression/","title":"Logistic Regression: The Workhorse of Production Classification","text":"<p>Top-Line Summary: Despite its name, Logistic Regression is a classification algorithm, not a regression algorithm. It is the industry standard \"baseline\" model. Before you build a massive Neural Network, you must build a Logistic Regression model first. If the Deep Learning model doesn't beat this by a significant margin, you ship the Logistic Regression.</p>"},{"location":"study/logistic_regression/#1-the-mathematical-intuition-the-professor","title":"1. The Mathematical Intuition (The Professor)","text":""},{"location":"study/logistic_regression/#the-problem-with-linear-regression-for-classification","title":"The Problem with Linear Regression for Classification","text":"<p>Imagine you are predicting if a transaction is Fraud (1) or Not Fraud (0). If you use standard Linear Regression (\\(y = mx + b\\)), the output can range from \\(-\\infty\\) to \\(+\\infty\\). * What does a prediction of \\(y = 150\\) mean? 15000% fraud? * What does \\(y = -0.5\\) mean? Negative probability?</p> <p>We need a function that maps any input value into a strict probability range of <code>[0, 1]</code>.</p>"},{"location":"study/logistic_regression/#the-solution-the-sigmoid-activation","title":"The Solution: The Sigmoid Activation","text":"<p>We take the output of the linear equation (\\(z\\)) and feed it into the Sigmoid Function (also called the Logistic Function).</p> \\[z = w \\cdot x + b\\] \\[\\hat{y} = \\sigma(z) = \\frac{1}{1 + e^{-z}}\\] <ul> <li>If \\(z\\) is very large positive: \\(e^{-z} \\approx 0\\), so \\(\\hat{y} \\approx 1\\).</li> <li>If \\(z\\) is very large negative: \\(e^{-z}\\) is huge, so \\(\\hat{y} \\approx 0\\).</li> <li>If \\(z = 0\\): \\(\\hat{y} = 0.5\\) (The uncertainty boundary).</li> </ul>"},{"location":"study/logistic_regression/#the-log-odds-the-hidden-linear-relationship","title":"The \"Log-Odds\" (The Hidden Linear Relationship)","text":"<p>This is the part most students miss. While the output is non-linear (the S-curve), the Log-Odds are linear. Rearranging the sigmoid equation gives us the Logit:</p> \\[\\ln \\left( \\frac{p}{1-p} \\right) = w \\cdot x + b\\] <ul> <li>\\(p\\): Probability of the positive class.</li> <li>\\(\\frac{p}{1-p}\\): The Odds (e.g., \"3 to 1 odds\").</li> <li>\\(\\ln(\\dots)\\): The Log-Odds.</li> </ul> <p>Why this matters: It makes the model interpretable. If weight \\(w_1 = 0.693\\), increasing feature \\(x_1\\) by 1 unit multiplies the odds of the positive outcome by \\(e^{0.693} \\approx 2\\).</p>"},{"location":"study/logistic_regression/#2-the-decision-boundary-visualizing-the-logic","title":"2. The Decision Boundary (Visualizing the Logic)","text":"<p>Logistic Regression is a Linear Classifier. This means it separates data points using a straight line (or a flat plane in 3D).</p> <ul> <li>If \\(w \\cdot x + b &gt; 0\\), the model predicts Class 1.</li> <li>If \\(w \\cdot x + b &lt; 0\\), the model predicts Class 0.</li> </ul> <p>The Bullseye Problem</p> <p>If your data resembles a \"bullseye\" (Class 0 in the middle, surrounded by Class 1), Logistic Regression will fail unless you engineer non-linear features (like \\(x^2\\)).</p>"},{"location":"study/logistic_regression/#3-the-cost-function-maximum-likelihood","title":"3. The Cost Function (Maximum Likelihood)","text":"<p>You cannot use Mean Squared Error (MSE) here. If you use MSE with the Sigmoid function, the error curve becomes \"wavy\" (non-convex), making it impossible for Gradient Descent to find the global minimum.</p> <p>Instead, we use Log Loss (Binary Cross-Entropy). This is derived from Maximum Likelihood Estimation (MLE)\u2014we want to find the weights that maximize the likelihood of observing the data we have.</p> \\[Cost = - \\frac{1}{m} \\sum_{i=1}^{m} [ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) ]\\] <ul> <li>If actual is \\(y=1\\), we want \\(\\hat{y}\\) close to 1 (so \\(\\log(\\hat{y})\\) is close to 0).</li> <li>If actual is \\(y=1\\) but model predicts \\(\\hat{y}=0.01\\), \\(\\log(0.01)\\) is a large negative number, creating a huge penalty.</li> </ul>"},{"location":"study/logistic_regression/#4-engineering-production-reality-the-principal-engineer","title":"4. Engineering &amp; Production Reality (The Principal Engineer)","text":"<p>When deploying Logistic Regression at Google-scale, we care about three things:</p>"},{"location":"study/logistic_regression/#a-latency-efficiency","title":"A. Latency &amp; Efficiency","text":"<p>Logistic Regression is incredibly fast. * Training: Highly parallelizable. * Inference: It is just a dot product followed by a simple math operation. We can serve millions of requests per second with minimal CPU usage.</p>"},{"location":"study/logistic_regression/#b-regularization-l1-vs-l2","title":"B. Regularization (L1 vs. L2)","text":"<p>In production, we almost never run \"vanilla\" Logistic Regression; we apply Regularization to prevent overfitting.</p> <ul> <li>L2 (Ridge): Shrinks all coefficients towards zero. Good for handling collinearity (correlated features).</li> <li>L1 (Lasso): Forces weak features to become exactly zero.</li> </ul> <p>Pro Tip: Automatic Feature Selection</p> <p>Use L1 Regularization when you have 10,000 features but suspect only 50 matter. It acts as automatic feature selection, making the model smaller and faster.</p>"},{"location":"study/logistic_regression/#c-calibration","title":"C. Calibration","text":"<p>Logistic Regression outputs are usually well-calibrated probabilities. If the model says \"70% chance of click,\" and we look at 1000 such cases, roughly 700 should actually be clicks. This is vital for Ads Bidding (where Expected Value = Probability \\(\\times\\) Bid).</p>"},{"location":"study/pca/","title":"Principal Component Analysis (PCA): The Art of Dimensionality Reduction","text":"<p>Top-Line Summary: PCA is an unsupervised learning algorithm used for dimensionality reduction.</p> <ul> <li>The Problem: You have a dataset with 1,000 columns (features). It is slow to train, hard to visualize, and prone to overfitting (The Curse of Dimensionality).</li> <li>The Solution: PCA compresses these 1,000 features into a smaller set (e.g., 50) of \"Principal Components\" while keeping as much of the original information (variance) as possible.</li> <li>The Analogy: Think of a 3D object (a teapot). If you want to capture it in a 2D photo, you rotate it to find the angle that shows the most detail (variance). You lose depth, but you keep the shape.</li> </ul>"},{"location":"study/pca/#1-the-mathematical-intuition-the-professor","title":"1. The Mathematical Intuition (The Professor)","text":""},{"location":"study/pca/#variance-information","title":"Variance = Information","text":"<p>In PCA, we assume that variance is synonymous with information. * If a feature is always equal to 5 (Variance = 0), it tells us nothing. We can drop it. * If a feature swings wildly from -100 to +100, it holds a lot of information about the differences between data points.</p>"},{"location":"study/pca/#the-goal-new-axes","title":"The Goal: New Axes","text":"<p>We want to find a new set of coordinate axes (Principal Components) to view our data.</p> <ul> <li>PC1 (First Principal Component): The direction in space where the data varies the most.</li> <li>PC2 (Second Principal Component): The direction of second-most variance, subject to the constraint that it must be orthogonal (90\u00b0 perpendicular) to PC1.</li> </ul>"},{"location":"study/pca/#eigenvectors-and-eigenvalues","title":"Eigenvectors and Eigenvalues","text":"<p>How do we find these axes? We use Linear Algebra. We calculate the Covariance Matrix of our data, which describes how features vary together. Then we compute:</p> <ul> <li>Eigenvectors: These point in the direction of the new axes (PC1, PC2, etc.).</li> <li>Eigenvalues: These represent the magnitude (amount of variance) explained by that axis.</li> </ul> <p>Rule of thumb: If PC1 has an Eigenvalue of 50 and PC2 has an Eigenvalue of 5, PC1 contains 10x more information than PC2.</p>"},{"location":"study/pca/#2-the-steps-the-algorithm","title":"2. The Steps (The Algorithm)","text":"<ol> <li>Standardize the Data: (Crucial! See Engineering section).</li> <li>Compute Covariance Matrix:     $\\(\\Sigma = \\frac{1}{m} X^T X\\)$</li> <li>Compute Eigenvectors/Eigenvalues: Solve for vectors \\(v\\) where \\(\\Sigma v = \\lambda v\\).</li> <li>Sort and Select: Sort Eigenvalues from high to low. Pick the top \\(k\\) components that explain enough variance (e.g., 95%).</li> <li>Project: Transform the original data (\\(X\\)) onto the new axes (\\(Z\\)).     $\\(Z = X \\cdot W\\)$     (Where \\(W\\) is the matrix of selected eigenvectors).</li> </ol>"},{"location":"study/pca/#3-engineering-production-reality-the-principal-engineer","title":"3. Engineering &amp; Production Reality (The Principal Engineer)","text":""},{"location":"study/pca/#a-the-scaling-trap-critical-alert","title":"A. The \"Scaling\" Trap (Critical Alert)","text":"<p>CRITICAL: You must normalize data first</p> <p>Scenario: You have two features: \"Distance (meters)\" and \"Weight (grams)\".</p> <ul> <li>The Bug: Weight might range from 0 to 1,000,000. Distance might range from 0 to 100.</li> <li>The Result: Since PCA looks for variance, it will think \"Weight\" is the only thing that matters because the numbers are huge. It will ignore \"Distance.\"</li> <li>The Fix: Use <code>StandardScaler</code> to force all features to Mean=0, Variance=1.</li> </ul>"},{"location":"study/pca/#b-the-black-box-trade-off","title":"B. The \"Black Box\" Trade-off","text":"<p>PCA creates new features that are linear combinations of old ones. * Original: \"Age\", \"Income\", \"Debt\". * PC1: \\(0.5 \\times Age + 0.3 \\times Income - 0.2 \\times Debt\\).</p> <p>Lost Interpretability</p> <p>You can no longer tell your Product Manager, \"The model predicts churn because of Age.\" You have to say, \"Because of Principal Component 1.\" This loss of interpretability is the price you pay for efficiency.</p>"},{"location":"study/pca/#c-use-case-anomaly-detection","title":"C. Use Case: Anomaly Detection","text":"<p>We use PCA for fraud detection in a clever way.</p> <ol> <li>Train PCA on \"Normal\" data.</li> <li>Compress a new transaction to low dimensions, then decompress it back (inverse transform).</li> <li>Reconstruction Error: If the transaction was \"Normal\", the reconstruction is good. If it is \"Fraud\" (an outlier), PCA fails to reconstruct it accurately. High error = Fraud.</li> </ol>"},{"location":"study/random_forest/","title":"Random Forest: The Wisdom of the Crowd (Ensemble Learning)","text":"<p>Top-Line Summary: If a Decision Tree is a single expert who might be opinionated and wrong (high variance), a Random Forest is a committee of 100 experts. Even if individual experts are wrong, the \"majority vote\" of the committee is usually right.</p> <ul> <li>Technique: Bagging (Bootstrap Aggregating) + Feature Randomness.</li> <li>The Superpower: Extremely resistant to overfitting. It works \"out of the box\" on almost any tabular dataset.</li> <li>The Trade-off: The model becomes a \"Black Box\" (harder to interpret) and inference can be slow (you have to ask 100 trees for an answer).</li> </ul>"},{"location":"study/random_forest/#1-the-intuition-democracy-of-trees-the-professor","title":"1. The Intuition: \"Democracy of Trees\" (The Professor)","text":"<p>Imagine you want to predict if a stock will go up.</p> <ul> <li>Single Tree: You ask one analyst. They might be obsessed with tech stocks and biased.</li> <li>Random Forest: You ask 100 analysts.<ul> <li>Analyst A looks at Price-to-Earnings ratio.</li> <li>Analyst B looks at Market Volume.</li> <li>Analyst C looks at recent News.</li> </ul> </li> </ul> <p>If 70 analysts say \"Buy\" and 30 say \"Sell,\" the model predicts \"Buy.\"</p>"},{"location":"study/random_forest/#the-core-mechanism-bagging","title":"The Core Mechanism: Bagging","text":"<p>Bagging stands for Bootstrap Aggregating.</p> <ol> <li>Bootstrapping: We create 100 different datasets from our original training data by sampling with replacement. Some rows appear multiple times in a dataset; others don't appear at all.</li> <li>Aggregating: We train a separate Decision Tree on each dataset. For regression, we average their outputs. For classification, we take a majority vote.</li> </ol>"},{"location":"study/random_forest/#the-secret-sauce-feature-randomness","title":"The Secret Sauce: Feature Randomness","text":"<p>This is the critical difference between a standard \"Bagged Tree\" and a \"Random Forest.\"</p> <p>If we just bootstrapped the data, the trees would still look very similar because the strong features (e.g., \"Income\" in a loan model) would be chosen by every tree at the top split.</p> <p>To fix this, Random Forest forces diversity: At every split inside a tree, the algorithm is only allowed to choose from a random subset of features (usually \\(\\sqrt{Total \\ Features}\\)). This forces some trees to make decisions without the strongest feature, allowing them to capture subtle patterns in less dominant features.</p>"},{"location":"study/random_forest/#2-the-math-variance-reduction","title":"2. The Math: Variance Reduction","text":"<p>Why does averaging trees work? Recall that a single fully-grown Decision Tree has Low Bias but High Variance (it fits the noise).</p> <p>The variance of the average of \\(n\\) independent random variables is:</p> \\[Var(\\bar{X}) = \\frac{\\sigma^2}{n}\\] <p>By averaging \\(n\\) trees, we reduce the variance of the prediction. Even though individual trees are noisy, their errors tend to cancel each other out (assuming the trees are uncorrelated).</p>"},{"location":"study/random_forest/#3-engineering-production-reality-the-principal-engineer","title":"3. Engineering &amp; Production Reality (The Principal Engineer)","text":""},{"location":"study/random_forest/#a-parallelization-the-speed-advantage","title":"A. Parallelization (The Speed Advantage)","text":"<p>Unlike Boosting (where trees are built sequentially, one correcting the other), Random Forest trees are independent.</p> <ul> <li>Implication: We can train all 100 trees simultaneously.</li> </ul> <p>Engineering Tip: Speed it up</p> <p>Set <code>n_jobs=-1</code> in your code (scikit-learn). This tells the server to use all available CPU cores. On a 64-core Google Cloud server, this makes training 64x faster.</p>"},{"location":"study/random_forest/#b-out-of-bag-oob-evaluation","title":"B. Out-of-Bag (OOB) Evaluation","text":"<p>Because we sample with replacement (Bootstrapping), about 37% of the data is never seen by a specific tree. This is called the \"Out-of-Bag\" data. We can use this leftover data to validate that specific tree.</p> <p>Pro Tip: Built-in Validation</p> <p>This acts as a built-in \"Cross-Validation.\" You can get a reliable error metric without manually setting aside a validation set (great for small datasets).</p>"},{"location":"study/random_forest/#c-inference-latency-the-hidden-cost","title":"C. Inference Latency (The Hidden Cost)","text":"<p>This is where Random Forest hurts in production.</p> <ul> <li>Linear Model: \\(y = mx+b\\) (1 calculation).</li> <li>Random Forest: You must pass the data through 100 (or 500) deep trees.</li> </ul> <p>Latency Warning</p> <p>If you have a strict &lt;10ms latency SLA (Service Level Agreement), a massive Random Forest might be too slow. You might need to distill it or use fewer trees.</p>"},{"location":"study/quiz/ml-quiz/","title":"\ud83e\udde0 Repeat Threepeat","text":"Topic QUESTION ANSWER <p>Loading answers...</p> \u2190 Prev 0 / 0 Next \u2192"},{"location":"study/quiz/ml-quiz/#question-text","title":"Loading questions...","text":"<p>(Click to flip)</p>"},{"location":"taste/cooking/","title":"Algorithm of Taste - Cooking Log","text":"<p>Automated process once a new picture is added</p>"},{"location":"taste/cooking/#2026-01-25-lettuce-soy-gue-ran-ma-ri","title":"\ud83d\udcc5 2026-01-25 : Lettuce Soy Gue-Ran Ma-Ri","text":"<p>\ud83d\udcdd Note: Tried Putting Lettuce</p> <p>Tags: <code>#Lettuce</code> <code>#Soy</code></p> <p></p>"},{"location":"taste/cooking/#2026-01-19-tofu-blueberry-spread-gue-ran-ma-ri","title":"\ud83d\udcc5 2026-01-19 : Tofu &amp; Blueberry Spread Gue-Ran Ma-Ri","text":"<p>\ud83d\udcdd Note: Without jam</p> <p>Tags: <code>#Tofu</code> <code>#Gue-Ran Ma-Ri</code></p> <p></p>"},{"location":"taste/cooking/#2026-01-19-tofu-blueberry-spread-gue-ran-ma-ri_1","title":"\ud83d\udcc5 2026-01-19 : Tofu &amp; Blueberry Spread Gue-Ran Ma-Ri","text":"<p>Tags: <code>#Tofu</code> <code>#Blueberry Spread</code> <code>#Gue-Ran Ma-Ri</code></p> <p></p>"},{"location":"taste/cooking/#2026-01-19-tofu-blueberry-spread-gue-ran-ma-ri_2","title":"\ud83d\udcc5 2026-01-19 : Tofu &amp; Blueberry Spread Gue-Ran Ma-Ri","text":"<p>Tags: <code>#Tofu</code> <code>#Blueberry Spread</code> <code>#Gue-Ran Ma-Ri</code></p> <p></p>"},{"location":"taste/cooking/#2026-01-17-tomato-sauce-filled-gue-ran-ma-ri","title":"\ud83d\udcc5 2026-01-17 : Tomato Sauce Filled Gue-Ran Ma-Ri","text":"<p>\ud83d\udcdd Note: Found a way to consume remaining tomato sauce!</p> <p>Tags: <code>#Tomato Sauce</code> <code>#Gue-Ran Ma-Ri</code></p> <p></p>"},{"location":"taste/cooking/#2026-01-15-shrimp-gue-ran-ma-ri","title":"\ud83d\udcc5 2026-01-15 : Shrimp Gue-Ran Ma-Ri","text":"<p>\ud83d\udcdd Note: Mashed shrimp Gue-Ran Ma-Ri</p> <p>Tags: <code>#Shrimp</code> <code>#Gue-Ran Ma-Ri</code></p> <p></p>"},{"location":"taste/cooking/#2026-01-12-cod-roe-gue-ran-ma-ri","title":"\ud83d\udcc5 2026-01-12 : Cod Roe Gue-Ran Ma-Ri","text":"<p>\ud83d\udcdd Note: Started to try various types of Gue-Ran Ma-Ri</p> <p>Tags: <code>#Cod Roe</code> <code>#Mayo</code> <code>#Gue-Ran Ma-Ri</code></p> <p></p>"},{"location":"taste/cooking/#2026-01-11-getting-interested-in-gue-ran-ma-ri","title":"\ud83d\udcc5 2026-01-11 : Getting interested in Gue-Ran Ma-Ri","text":"<p>\ud83d\udcdd Note: Leek Added</p> <p>Tags: <code>#Leek</code> <code>#Honey</code> <code>#Gue-Ran Ma-Ri</code></p> <p></p>"},{"location":"taste/cooking/#2025-12-29-first-ever-gue-ran-ma-ri","title":"\ud83d\udcc5 2025-12-29 : First Ever Gue-Ran Ma-Ri","text":"<p>\ud83d\udcdd Note: First attempt of making Gue-Ran Ma-Ri</p> <p>Tags: <code>#Korean Egg Rolls</code> <code>#Gue-Ran Ma-Ri</code></p> <p></p>"},{"location":"taste/cooking/#2025-12-25-campfire-chicken-wings","title":"\ud83d\udcc5 2025-12-25 : Campfire chicken wings","text":"<p>\ud83d\udcdd Note: BBQ Wings</p> <p>Tags: <code>#BBQ</code> <code>#Wings</code> <code>#Campfire</code></p> <p></p>"}]}